from dotenv import load_dotenv
import os

# Load environment variables
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GITHUB_API_KEY = os.getenv("GITHUB_API_KEY")
CEREBRAS_API_KEY = os.getenv("CEREBRAS_API_KEY")
LANGGRAPH_API_KEY = os.getenv("LANGGRAPH_API_KEY")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
KIMI_K2_API_KEY = os.getenv("KIMI_K2_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

OPENAI_GPT_4_1 = "gpt-4.1"
OPENAI_GPT_4_1_MINI = "gpt-4.1-mini"
OPENAI_GPT_5 = "gpt-5"
OPENAI_GPT_5_MINI = "gpt-5-mini"
OPENAI_GPT_5_NANO = "gpt-5-nano"
OPENAI_GPT_5_1 = "gpt-5.1-2025-11-13"
QWEN3_CODER_480B = "qwen-3-coder-480b"
CLAUDE_4_5_SONNET = "claude-sonnet-4-5"
KIMI_K2_TURBO_MODEL = "kimi-k2-turbo-preview"
KIMI_K2_THINKING_MODEL = "kimi-k2-thinking"
GEMINI_3_PRO_PREVIEW = "gemini-3-pro-preview"

PROVIDER_OPENAI = "openai"
PROVIDER_AZURE_OPENAI = "azure_openai"
PROVIDER_GITHUB = "openai"
PROVIDER_CEREBRAS = "openai"
PROVIDER_ANTHROPIC = "anthropic"
PROVIDER_KIMI = "openai"
PROVIDER_GEMINI = "google_genai"

OPENAI_BASE_URL = "https://api.openai.com/v1"
GITHUB_BASE_URL = "https://models.github.ai/inference"
CEREBRAS_BASE_URL = "https://api.cerebras.ai/v1"
ANTHROPIC_BASE_URL = "https://api.anthropic.com/v1"
KIMI_BASE_URL = "https://api.moonshot.ai/v1"
GEMINI_BASE_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent?key=" + GEMINI_API_KEY

SCOPE_MODEL = OPENAI_GPT_4_1
if SCOPE_MODEL == CLAUDE_4_5_SONNET:
    SCOPE_MODEL_NAME = CLAUDE_4_5_SONNET
    SCOPE_MODEL_PROVIDER = PROVIDER_ANTHROPIC
    SCOPE_MODEL_BASE_URL = ANTHROPIC_BASE_URL
    SCOPE_MODEL_TEMPERATURE = 0.0
    SCOPE_MODEL_PROVIDER_API_KEY = ANTHROPIC_API_KEY
    SCOPE_MODEL_MAX_TOKENS = None
elif SCOPE_MODEL == OPENAI_GPT_5_1:
    SCOPE_MODEL_NAME = OPENAI_GPT_5_1
    SCOPE_MODEL_PROVIDER = PROVIDER_OPENAI
    SCOPE_MODEL_BASE_URL = OPENAI_BASE_URL
    SCOPE_MODEL_TEMPERATURE = 0.0
    SCOPE_MODEL_PROVIDER_API_KEY = OPENAI_API_KEY
    SCOPE_MODEL_MAX_TOKENS = None
elif SCOPE_MODEL == OPENAI_GPT_4_1:
    SCOPE_MODEL_NAME = OPENAI_GPT_4_1
    SCOPE_MODEL_PROVIDER = PROVIDER_OPENAI
    SCOPE_MODEL_BASE_URL = OPENAI_BASE_URL
    SCOPE_MODEL_TEMPERATURE = 0.0
    SCOPE_MODEL_PROVIDER_API_KEY = OPENAI_API_KEY
    SCOPE_MODEL_MAX_TOKENS = None
elif SCOPE_MODEL == GEMINI_3_PRO_PREVIEW:
    SCOPE_MODEL_NAME = GEMINI_3_PRO_PREVIEW
    SCOPE_MODEL_PROVIDER = PROVIDER_GEMINI
    SCOPE_MODEL_BASE_URL = GEMINI_BASE_URL
    SCOPE_MODEL_TEMPERATURE = 0.0
    SCOPE_MODEL_PROVIDER_API_KEY = GEMINI_API_KEY
    SCOPE_MODEL_MAX_TOKENS = None
elif SCOPE_MODEL == KIMI_K2_THINKING_MODEL:
    SCOPE_MODEL_NAME = KIMI_K2_THINKING_MODEL
    SCOPE_MODEL_PROVIDER = PROVIDER_KIMI
    SCOPE_MODEL_BASE_URL = KIMI_BASE_URL
    SCOPE_MODEL_TEMPERATURE = 0.0
    SCOPE_MODEL_PROVIDER_API_KEY = KIMI_K2_API_KEY
    SCOPE_MODEL_MAX_TOKENS = None
else:
    raise ValueError(f"Invalid scope model: {SCOPE_MODEL}")

TEST_MODEL = OPENAI_GPT_4_1
if TEST_MODEL == CLAUDE_4_5_SONNET:
    TEST_SCOPE_MODEL_NAME = CLAUDE_4_5_SONNET
    TEST_SCOPE_MODEL_PROVIDER = PROVIDER_ANTHROPIC
    TEST_SCOPE_MODEL_BASE_URL = ANTHROPIC_BASE_URL
    TEST_SCOPE_MODEL_TEMPERATURE = 0.0
    TEST_SCOPE_MODEL_PROVIDER_API_KEY = ANTHROPIC_API_KEY
    TEST_SCOPE_MODEL_MAX_TOKENS = None
elif TEST_MODEL == OPENAI_GPT_5_1:
    TEST_SCOPE_MODEL_NAME = OPENAI_GPT_5_1
    TEST_SCOPE_MODEL_PROVIDER = PROVIDER_OPENAI
    TEST_SCOPE_MODEL_BASE_URL = OPENAI_BASE_URL
    TEST_SCOPE_MODEL_TEMPERATURE = 0.0
    TEST_SCOPE_MODEL_PROVIDER_API_KEY = OPENAI_API_KEY
    TEST_SCOPE_MODEL_MAX_TOKENS = None
elif TEST_MODEL == OPENAI_GPT_4_1:
    TEST_SCOPE_MODEL_NAME = OPENAI_GPT_4_1
    TEST_SCOPE_MODEL_PROVIDER = PROVIDER_OPENAI
    TEST_SCOPE_MODEL_BASE_URL = OPENAI_BASE_URL
    TEST_SCOPE_MODEL_TEMPERATURE = 0.0
    TEST_SCOPE_MODEL_PROVIDER_API_KEY = OPENAI_API_KEY
    TEST_SCOPE_MODEL_MAX_TOKENS = None
elif TEST_MODEL == GEMINI_3_PRO_PREVIEW:
    TEST_SCOPE_MODEL_NAME = GEMINI_3_PRO_PREVIEW
    TEST_SCOPE_MODEL_PROVIDER = PROVIDER_GEMINI
    TEST_SCOPE_MODEL_BASE_URL = GEMINI_BASE_URL
    TEST_SCOPE_MODEL_TEMPERATURE = 0.0
    TEST_SCOPE_MODEL_PROVIDER_API_KEY = GEMINI_API_KEY
    TEST_SCOPE_MODEL_MAX_TOKENS = None
elif TEST_MODEL == KIMI_K2_THINKING_MODEL:
    TEST_SCOPE_MODEL_NAME = KIMI_K2_THINKING_MODEL
    TEST_SCOPE_MODEL_PROVIDER = PROVIDER_KIMI
    TEST_SCOPE_MODEL_BASE_URL = KIMI_BASE_URL
    TEST_SCOPE_MODEL_TEMPERATURE = 0.0
    TEST_SCOPE_MODEL_PROVIDER_API_KEY = KIMI_K2_API_KEY
    TEST_SCOPE_MODEL_MAX_TOKENS = None
else:
    raise ValueError(f"Invalid test model: {TEST_MODEL}")

RESEARCH_MODEL = CLAUDE_4_5_SONNET
if RESEARCH_MODEL == CLAUDE_4_5_SONNET:
    RESEARCH_MODEL_NAME = CLAUDE_4_5_SONNET
    RESEARCH_MODEL_PROVIDER = PROVIDER_ANTHROPIC
    RESEARCH_MODEL_BASE_URL = ANTHROPIC_BASE_URL
    RESEARCH_MODEL_TEMPERATURE = 0.0
    RESEARCH_MODEL_PROVIDER_API_KEY = ANTHROPIC_API_KEY
    RESEARCH_MODEL_MAX_TOKENS = 4096
elif RESEARCH_MODEL == OPENAI_GPT_5_1:
    RESEARCH_MODEL_NAME = OPENAI_GPT_5_1
    RESEARCH_MODEL_PROVIDER = PROVIDER_OPENAI
    RESEARCH_MODEL_BASE_URL = OPENAI_BASE_URL
    RESEARCH_MODEL_TEMPERATURE = 0.0
    RESEARCH_MODEL_PROVIDER_API_KEY = OPENAI_API_KEY
    RESEARCH_MODEL_MAX_TOKENS = 4096
elif RESEARCH_MODEL == GEMINI_3_PRO_PREVIEW:
    RESEARCH_MODEL_NAME = GEMINI_3_PRO_PREVIEW
    RESEARCH_MODEL_PROVIDER = PROVIDER_GEMINI
    RESEARCH_MODEL_BASE_URL = GEMINI_BASE_URL
    RESEARCH_MODEL_TEMPERATURE = 0.0
    RESEARCH_MODEL_PROVIDER_API_KEY = GEMINI_API_KEY
    RESEARCH_MODEL_MAX_TOKENS = 4096
elif RESEARCH_MODEL == KIMI_K2_THINKING_MODEL:
    RESEARCH_MODEL_NAME = KIMI_K2_THINKING_MODEL
    RESEARCH_MODEL_PROVIDER = PROVIDER_KIMI
    RESEARCH_MODEL_BASE_URL = KIMI_BASE_URL
    RESEARCH_MODEL_TEMPERATURE = 0.0
    RESEARCH_MODEL_PROVIDER_API_KEY = KIMI_K2_API_KEY
    RESEARCH_MODEL_MAX_TOKENS = 4096
else:
    raise ValueError(f"Invalid research model: {RESEARCH_MODEL}")

SUMMARIZATION_MODEL = OPENAI_GPT_4_1_MINI
if SUMMARIZATION_MODEL == CLAUDE_4_5_SONNET:
    SUMMARIZATION_MODEL_NAME = CLAUDE_4_5_SONNET
    SUMMARIZATION_MODEL_PROVIDER = PROVIDER_ANTHROPIC
    SUMMARIZATION_MODEL_BASE_URL = ANTHROPIC_BASE_URL
    SUMMARIZATION_MODEL_TEMPERATURE = 0.0
    SUMMARIZATION_MODEL_PROVIDER_API_KEY = ANTHROPIC_API_KEY
    SUMMARIZATION_MODEL_MAX_TOKENS = None
elif SUMMARIZATION_MODEL == OPENAI_GPT_5_1:
    SUMMARIZATION_MODEL_NAME = OPENAI_GPT_5_1
    SUMMARIZATION_MODEL_PROVIDER = PROVIDER_OPENAI
    SUMMARIZATION_MODEL_BASE_URL = OPENAI_BASE_URL
    SUMMARIZATION_MODEL_TEMPERATURE = 0.0
    SUMMARIZATION_MODEL_PROVIDER_API_KEY = OPENAI_API_KEY
    SUMMARIZATION_MODEL_MAX_TOKENS = None
elif SUMMARIZATION_MODEL == GEMINI_3_PRO_PREVIEW:
    SUMMARIZATION_MODEL_NAME = GEMINI_3_PRO_PREVIEW
    SUMMARIZATION_MODEL_PROVIDER = PROVIDER_GEMINI
    SUMMARIZATION_MODEL_BASE_URL = GEMINI_BASE_URL
    SUMMARIZATION_MODEL_TEMPERATURE = 0.0
    SUMMARIZATION_MODEL_PROVIDER_API_KEY = GEMINI_API_KEY
    SUMMARIZATION_MODEL_MAX_TOKENS = None
elif SUMMARIZATION_MODEL == KIMI_K2_THINKING_MODEL:
    SUMMARIZATION_MODEL_NAME = KIMI_K2_THINKING_MODEL
    SUMMARIZATION_MODEL_PROVIDER = PROVIDER_KIMI
    SUMMARIZATION_MODEL_BASE_URL = KIMI_BASE_URL
    SUMMARIZATION_MODEL_TEMPERATURE = 0.0
    SUMMARIZATION_MODEL_PROVIDER_API_KEY = KIMI_K2_API_KEY
    SUMMARIZATION_MODEL_MAX_TOKENS = None
elif SUMMARIZATION_MODEL == OPENAI_GPT_4_1_MINI:
    SUMMARIZATION_MODEL_NAME = OPENAI_GPT_4_1_MINI
    SUMMARIZATION_MODEL_PROVIDER = PROVIDER_OPENAI
    SUMMARIZATION_MODEL_BASE_URL = OPENAI_BASE_URL
    SUMMARIZATION_MODEL_TEMPERATURE = 0.0
    SUMMARIZATION_MODEL_PROVIDER_API_KEY = OPENAI_API_KEY
    SUMMARIZATION_MODEL_MAX_TOKENS = None
else:
    raise ValueError(f"Invalid summarization model: {SUMMARIZATION_MODEL}")

COMPRESS_MODEL = OPENAI_GPT_4_1
if COMPRESS_MODEL == CLAUDE_4_5_SONNET:
    COMPRESS_MODEL_NAME = CLAUDE_4_5_SONNET
    COMPRESS_MODEL_PROVIDER = PROVIDER_ANTHROPIC
    COMPRESS_MODEL_BASE_URL = ANTHROPIC_BASE_URL
    COMPRESS_MODEL_TEMPERATURE = 0.0
    COMPRESS_MODEL_PROVIDER_API_KEY = ANTHROPIC_API_KEY
    COMPRESS_MODEL_MAX_TOKENS = 32000
elif COMPRESS_MODEL == OPENAI_GPT_5_1:
    COMPRESS_MODEL_NAME = OPENAI_GPT_5_1
    COMPRESS_MODEL_PROVIDER = PROVIDER_OPENAI
    COMPRESS_MODEL_BASE_URL = OPENAI_BASE_URL
    COMPRESS_MODEL_TEMPERATURE = 0.0
    COMPRESS_MODEL_PROVIDER_API_KEY = OPENAI_API_KEY
    COMPRESS_MODEL_MAX_TOKENS = 32000
elif COMPRESS_MODEL == OPENAI_GPT_4_1:
    COMPRESS_MODEL_NAME = OPENAI_GPT_4_1
    COMPRESS_MODEL_PROVIDER = PROVIDER_OPENAI
    COMPRESS_MODEL_BASE_URL = OPENAI_BASE_URL
    COMPRESS_MODEL_TEMPERATURE = 0.0
    COMPRESS_MODEL_PROVIDER_API_KEY = OPENAI_API_KEY
    COMPRESS_MODEL_MAX_TOKENS = 32000
elif COMPRESS_MODEL == GEMINI_3_PRO_PREVIEW:
    COMPRESS_MODEL_NAME = GEMINI_3_PRO_PREVIEW
    COMPRESS_MODEL_PROVIDER = PROVIDER_GEMINI
    COMPRESS_MODEL_BASE_URL = GEMINI_BASE_URL
    COMPRESS_MODEL_TEMPERATURE = 0.0
    COMPRESS_MODEL_PROVIDER_API_KEY = GEMINI_API_KEY
    COMPRESS_MODEL_MAX_TOKENS = 32000
elif COMPRESS_MODEL == KIMI_K2_THINKING_MODEL:
    COMPRESS_MODEL_NAME = KIMI_K2_THINKING_MODEL
    COMPRESS_MODEL_PROVIDER = PROVIDER_KIMI
    COMPRESS_MODEL_BASE_URL = KIMI_BASE_URL
    COMPRESS_MODEL_TEMPERATURE = 0.0
    COMPRESS_MODEL_PROVIDER_API_KEY = KIMI_K2_API_KEY
    COMPRESS_MODEL_MAX_TOKENS = 32000
else:
    raise ValueError(f"Invalid compress model: {COMPRESS_MODEL}")

SUPERVISOR_MODEL = CLAUDE_4_5_SONNET
if SUPERVISOR_MODEL == CLAUDE_4_5_SONNET:
    SUPERVISOR_MODEL_NAME = CLAUDE_4_5_SONNET
    SUPERVISOR_MODEL_PROVIDER = PROVIDER_ANTHROPIC
    SUPERVISOR_MODEL_BASE_URL = ANTHROPIC_BASE_URL
    SUPERVISOR_MODEL_TEMPERATURE = 0.0
    SUPERVISOR_MODEL_PROVIDER_API_KEY = ANTHROPIC_API_KEY
    SUPERVISOR_MODEL_MAX_TOKENS = 4096
elif SUPERVISOR_MODEL == OPENAI_GPT_5_1:
    SUPERVISOR_MODEL_NAME = OPENAI_GPT_5_1
    SUPERVISOR_MODEL_PROVIDER = PROVIDER_OPENAI
    SUPERVISOR_MODEL_BASE_URL = OPENAI_BASE_URL
    SUPERVISOR_MODEL_TEMPERATURE = 0.0
    SUPERVISOR_MODEL_PROVIDER_API_KEY = OPENAI_API_KEY
    SUPERVISOR_MODEL_MAX_TOKENS = 4096
elif SUPERVISOR_MODEL == GEMINI_3_PRO_PREVIEW:
    SUPERVISOR_MODEL_NAME = GEMINI_3_PRO_PREVIEW
    SUPERVISOR_MODEL_PROVIDER = PROVIDER_GEMINI
    SUPERVISOR_MODEL_BASE_URL = GEMINI_BASE_URL
    SUPERVISOR_MODEL_TEMPERATURE = 0.0
    SUPERVISOR_MODEL_PROVIDER_API_KEY = GEMINI_API_KEY
    SUPERVISOR_MODEL_MAX_TOKENS = 4096
elif SUPERVISOR_MODEL == KIMI_K2_THINKING_MODEL:
    SUPERVISOR_MODEL_NAME = KIMI_K2_THINKING_MODEL
    SUPERVISOR_MODEL_PROVIDER = PROVIDER_KIMI
    SUPERVISOR_MODEL_BASE_URL = KIMI_BASE_URL
    SUPERVISOR_MODEL_TEMPERATURE = 0.0
    SUPERVISOR_MODEL_PROVIDER_API_KEY = KIMI_K2_API_KEY
    SUPERVISOR_MODEL_MAX_TOKENS = 4096
else:
    raise ValueError(f"Invalid supervisor model: {SUPERVISOR_MODEL}")

WRITER_MODEL = OPENAI_GPT_4_1
if WRITER_MODEL == CLAUDE_4_5_SONNET:
    WRITER_MODEL_NAME = CLAUDE_4_5_SONNET
    WRITER_MODEL_PROVIDER = PROVIDER_ANTHROPIC
    WRITER_MODEL_BASE_URL = ANTHROPIC_BASE_URL
    WRITER_MODEL_TEMPERATURE = 0.0
    WRITER_MODEL_PROVIDER_API_KEY = ANTHROPIC_API_KEY
    WRITER_MODEL_MAX_TOKENS = 32000
elif WRITER_MODEL == OPENAI_GPT_5_1:
    WRITER_MODEL_NAME = OPENAI_GPT_5_1
    WRITER_MODEL_PROVIDER = PROVIDER_OPENAI
    WRITER_MODEL_BASE_URL = OPENAI_BASE_URL
    WRITER_MODEL_TEMPERATURE = 0.0
    WRITER_MODEL_PROVIDER_API_KEY = OPENAI_API_KEY
    WRITER_MODEL_MAX_TOKENS = 32000
elif WRITER_MODEL == OPENAI_GPT_4_1:
    WRITER_MODEL_NAME = OPENAI_GPT_4_1
    WRITER_MODEL_PROVIDER = PROVIDER_OPENAI
    WRITER_MODEL_BASE_URL = OPENAI_BASE_URL
    WRITER_MODEL_TEMPERATURE = 0.0
    WRITER_MODEL_PROVIDER_API_KEY = OPENAI_API_KEY
    WRITER_MODEL_MAX_TOKENS = 32000
elif WRITER_MODEL == GEMINI_3_PRO_PREVIEW:
    WRITER_MODEL_NAME = GEMINI_3_PRO_PREVIEW
    WRITER_MODEL_PROVIDER = PROVIDER_GEMINI
    WRITER_MODEL_BASE_URL = GEMINI_BASE_URL
    WRITER_MODEL_TEMPERATURE = 0.0
    WRITER_MODEL_PROVIDER_API_KEY = GEMINI_API_KEY
    WRITER_MODEL_MAX_TOKENS = 32000
elif WRITER_MODEL == KIMI_K2_THINKING_MODEL:
    WRITER_MODEL_NAME = KIMI_K2_THINKING_MODEL
    WRITER_MODEL_PROVIDER = PROVIDER_KIMI
    WRITER_MODEL_BASE_URL = KIMI_BASE_URL
    WRITER_MODEL_TEMPERATURE = 0.0
    WRITER_MODEL_PROVIDER_API_KEY = KIMI_K2_API_KEY
    WRITER_MODEL_MAX_TOKENS = 32000
else:
    raise ValueError(f"Invalid writer model: {WRITER_MODEL}")

