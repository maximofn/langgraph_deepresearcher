**MCP's 1st Birthday Hackathon**

[Watch Now ‚Üí](https://www.youtube.com/watch?v=6C2JRt2Wi5o)

[![Gradio logo](/_app/immutable/assets/gradio.CHB5adID.svg)](/)  [‚ö° Quickstart](/guides/quickstart) [‚úçÔ∏è Docs](/docs) [üé¢ Playground](/playground) [üñºÔ∏è Custom Components](/custom-components/gallery)

üñê Community

Search Search

‚åòK

Getting Started

[Quickstart](../guides/quickstart/)

Building Interfaces

[The Interface Class](../guides/the-interface-class/)[More On Examples](../guides/more-on-examples/)[Flagging](../guides/flagging/)[Interface State](../guides/interface-state/)[Reactive Interfaces](../guides/reactive-interfaces/)[Four Kinds Of Interfaces](../guides/four-kinds-of-interfaces/)

Building With Blocks

[Blocks And Event Listeners](../guides/blocks-and-event-listeners/)[Controlling Layout](../guides/controlling-layout/)[State In Blocks](../guides/state-in-blocks/)[Dynamic Apps With Render Decorator](../guides/dynamic-apps-with-render-decorator/)[More Blocks Features](../guides/more-blocks-features/)[Custom CSS And JS](../guides/custom-CSS-and-JS/)[Using Blocks Like Functions](../guides/using-blocks-like-functions/)

Additional Features

[Queuing](../guides/queuing/)[Streaming Outputs](../guides/streaming-outputs/)[Streaming Inputs](../guides/streaming-inputs/)[Alerts](../guides/alerts/)[Progress Bars](../guides/progress-bars/)[Batch Functions](../guides/batch-functions/)[Sharing Your App](../guides/sharing-your-app/)[File Access](../guides/file-access/)[Multipage Apps](../guides/multipage-apps/)[Environment Variables](../guides/environment-variables/)[Resource Cleanup](../guides/resource-cleanup/)[Themes](../guides/themes/)[Client Side Functions](../guides/client-side-functions/)[View Api Page](../guides/view-api-page/)[Internationalization](../guides/internationalization/)

Chatbots

[Creating A Chatbot Fast](../guides/creating-a-chatbot-fast/)[Chatinterface Examples](../guides/chatinterface-examples/)[Agents And Tool Usage](../guides/agents-and-tool-usage/)[Creating A Custom Chatbot With Blocks](../guides/creating-a-custom-chatbot-with-blocks/)[Chatbot Specific Events](../guides/chatbot-specific-events/)[Creating A Discord Bot From A Gradio App](../guides/creating-a-discord-bot-from-a-gradio-app/)[Creating A Slack Bot From A Gradio App](../guides/creating-a-slack-bot-from-a-gradio-app/)[Creating A Website Widget From A Gradio Chatbot](../guides/creating-a-website-widget-from-a-gradio-chatbot/)

Data Science And Plots

[Creating Plots](../guides/creating-plots/)[Time Plots](../guides/time-plots/)[Filters Tables And Stats](../guides/filters-tables-and-stats/)[Connecting To A Database](../guides/connecting-to-a-database/)

Streaming

[Streaming Ai Generated Audio](../guides/streaming-ai-generated-audio/)[Object Detection From Webcam With Webrtc](../guides/object-detection-from-webcam-with-webrtc/)[Object Detection From Video](../guides/object-detection-from-video/)[Conversational Chatbot](../guides/conversational-chatbot/)[Real Time Speech Recognition](../guides/real-time-speech-recognition/)[Automatic Voice Detection](../guides/automatic-voice-detection/)

Custom Components

[Custom Components In Five Minutes](../guides/custom-components-in-five-minutes/)[Key Component Concepts](../guides/key-component-concepts/)[Configuration](../guides/configuration/)[Backend](../guides/backend/)[Frontend](../guides/frontend/)[Frequently Asked Questions](../guides/frequently-asked-questions/)[Pdf Component Example](../guides/pdf-component-example/)[Multimodal Chatbot Part1](../guides/multimodal-chatbot-part1/)[Documenting Custom Components](../guides/documenting-custom-components/)

Gradio Clients And Lite

[Getting Started With The Python Client](../guides/getting-started-with-the-python-client/)[Getting Started With The Js Client](../guides/getting-started-with-the-js-client/)[Querying Gradio Apps With Curl](../guides/querying-gradio-apps-with-curl/)[Gradio And Llm Agents](../guides/gradio-and-llm-agents/)[Fastapi App With The Gradio Client](../guides/fastapi-app-with-the-gradio-client/)

Mcp

[Building Mcp Server With Gradio](../guides/building-mcp-server-with-gradio/)[File Upload Mcp](../guides/file-upload-mcp/)[Building An Mcp Client With Gradio](../guides/building-an-mcp-client-with-gradio/)[Using Docs Mcp](../guides/using-docs-mcp/)

Other Tutorials

[Using Hugging Face Integrations](../guides/using-hugging-face-integrations/)[Gradio And Comet](../guides/Gradio-and-Comet/)[Gradio And ONNX On Hugging Face](../guides/Gradio-and-ONNX-on-Hugging-Face/)[Gradio And Wandb Integration](../guides/Gradio-and-Wandb-Integration/)[Create Immersive Demo](../guides/create-immersive-demo/)[Create Your Own Friends With A Gan](../guides/create-your-own-friends-with-a-gan/)[Creating A Dashboard From Bigquery Data](../guides/creating-a-dashboard-from-bigquery-data/)[Creating A Dashboard From Supabase Data](../guides/creating-a-dashboard-from-supabase-data/)[Creating A Realtime Dashboard From Google Sheets](../guides/creating-a-realtime-dashboard-from-google-sheets/)[Deploying Gradio With Disco](../guides/deploying-gradio-with-disco/)[Deploying Gradio With Docker](../guides/deploying-gradio-with-docker/)[Deploying Gradio With Modal](../guides/deploying-gradio-with-modal/)[Developing Faster With Reload Mode](../guides/developing-faster-with-reload-mode/)[From Openapi Spec](../guides/from-openapi-spec/)[Gradio 6 Migration Guide](../guides/gradio-6-migration-guide/)[How To Use 3D Model Component](../guides/how-to-use-3D-model-component/)[Image Classification In Pytorch](../guides/image-classification-in-pytorch/)[Image Classification With Vision Transformers](../guides/image-classification-with-vision-transformers/)[Installing Gradio In A Virtual Environment](../guides/installing-gradio-in-a-virtual-environment/)[Named Entity Recognition](../guides/named-entity-recognition/)[Plot Component For Maps](../guides/plot-component-for-maps/)[Running Background Tasks](../guides/running-background-tasks/)[Running Gradio On Your Web Server With Nginx](../guides/running-gradio-on-your-web-server-with-nginx/)[Setting Up A Demo For Maximum Performance](../guides/setting-up-a-demo-for-maximum-performance/)[Styling The Gradio Dataframe](../guides/styling-the-gradio-dataframe/)[Theming Guide](../guides/theming-guide/)[Understanding Gradio Share Links](../guides/understanding-gradio-share-links/)[Using Flagging](../guides/using-flagging/)[Using Gradio For Tabular Workflows](../guides/using-gradio-for-tabular-workflows/)[Using Gradio In Other Programming Languages](../guides/using-gradio-in-other-programming-languages/)[Wrapping Layouts](../guides/wrapping-layouts/)

5.49.14.44.1main

Getting Started

[Quickstart](../guides/quickstart/)

Building Interfaces

[The Interface Class](../guides/the-interface-class/)[More On Examples](../guides/more-on-examples/)[Flagging](../guides/flagging/)[Interface State](../guides/interface-state/)[Reactive Interfaces](../guides/reactive-interfaces/)[Four Kinds Of Interfaces](../guides/four-kinds-of-interfaces/)

Building With Blocks

[Blocks And Event Listeners](../guides/blocks-and-event-listeners/)[Controlling Layout](../guides/controlling-layout/)[State In Blocks](../guides/state-in-blocks/)[Dynamic Apps With Render Decorator](../guides/dynamic-apps-with-render-decorator/)[More Blocks Features](../guides/more-blocks-features/)[Custom CSS And JS](../guides/custom-CSS-and-JS/)[Using Blocks Like Functions](../guides/using-blocks-like-functions/)

Additional Features

[Queuing](../guides/queuing/)[Streaming Outputs](../guides/streaming-outputs/)[Streaming Inputs](../guides/streaming-inputs/)[Alerts](../guides/alerts/)[Progress Bars](../guides/progress-bars/)[Batch Functions](../guides/batch-functions/)[Sharing Your App](../guides/sharing-your-app/)[File Access](../guides/file-access/)[Multipage Apps](../guides/multipage-apps/)[Environment Variables](../guides/environment-variables/)[Resource Cleanup](../guides/resource-cleanup/)[Themes](../guides/themes/)[Client Side Functions](../guides/client-side-functions/)[View Api Page](../guides/view-api-page/)[Internationalization](../guides/internationalization/)

Chatbots

[Creating A Chatbot Fast](../guides/creating-a-chatbot-fast/)[Chatinterface Examples](../guides/chatinterface-examples/)[Agents And Tool Usage](../guides/agents-and-tool-usage/)[Creating A Custom Chatbot With Blocks](../guides/creating-a-custom-chatbot-with-blocks/)[Chatbot Specific Events](../guides/chatbot-specific-events/)[Creating A Discord Bot From A Gradio App](../guides/creating-a-discord-bot-from-a-gradio-app/)[Creating A Slack Bot From A Gradio App](../guides/creating-a-slack-bot-from-a-gradio-app/)[Creating A Website Widget From A Gradio Chatbot](../guides/creating-a-website-widget-from-a-gradio-chatbot/)

Data Science And Plots

[Creating Plots](../guides/creating-plots/)[Time Plots](../guides/time-plots/)[Filters Tables And Stats](../guides/filters-tables-and-stats/)[Connecting To A Database](../guides/connecting-to-a-database/)

Streaming

[Streaming Ai Generated Audio](../guides/streaming-ai-generated-audio/)[Object Detection From Webcam With Webrtc](../guides/object-detection-from-webcam-with-webrtc/)[Object Detection From Video](../guides/object-detection-from-video/)

[Setting up the Model](#setting-up-the-model)[The Inference Function](#the-inference-function)[The Gradio Demo](#the-gradio-demo)[Conclusion](#conclusion)

[Conversational Chatbot](../guides/conversational-chatbot/)[Real Time Speech Recognition](../guides/real-time-speech-recognition/)[Automatic Voice Detection](../guides/automatic-voice-detection/)

Custom Components

[Custom Components In Five Minutes](../guides/custom-components-in-five-minutes/)[Key Component Concepts](../guides/key-component-concepts/)[Configuration](../guides/configuration/)[Backend](../guides/backend/)[Frontend](../guides/frontend/)[Frequently Asked Questions](../guides/frequently-asked-questions/)[Pdf Component Example](../guides/pdf-component-example/)[Multimodal Chatbot Part1](../guides/multimodal-chatbot-part1/)[Documenting Custom Components](../guides/documenting-custom-components/)

Gradio Clients And Lite

[Getting Started With The Python Client](../guides/getting-started-with-the-python-client/)[Getting Started With The Js Client](../guides/getting-started-with-the-js-client/)[Querying Gradio Apps With Curl](../guides/querying-gradio-apps-with-curl/)[Gradio And Llm Agents](../guides/gradio-and-llm-agents/)[Fastapi App With The Gradio Client](../guides/fastapi-app-with-the-gradio-client/)

Mcp

[Building Mcp Server With Gradio](../guides/building-mcp-server-with-gradio/)[File Upload Mcp](../guides/file-upload-mcp/)[Building An Mcp Client With Gradio](../guides/building-an-mcp-client-with-gradio/)[Using Docs Mcp](../guides/using-docs-mcp/)

Other Tutorials [ show ]

[Using Hugging Face Integrations](../guides/using-hugging-face-integrations/)[Gradio And Comet](../guides/Gradio-and-Comet/)[Gradio And ONNX On Hugging Face](../guides/Gradio-and-ONNX-on-Hugging-Face/)[Gradio And Wandb Integration](../guides/Gradio-and-Wandb-Integration/)[Create Immersive Demo](../guides/create-immersive-demo/)[Create Your Own Friends With A Gan](../guides/create-your-own-friends-with-a-gan/)[Creating A Dashboard From Bigquery Data](../guides/creating-a-dashboard-from-bigquery-data/)[Creating A Dashboard From Supabase Data](../guides/creating-a-dashboard-from-supabase-data/)[Creating A Realtime Dashboard From Google Sheets](../guides/creating-a-realtime-dashboard-from-google-sheets/)[Deploying Gradio With Disco](../guides/deploying-gradio-with-disco/)[Deploying Gradio With Docker](../guides/deploying-gradio-with-docker/)[Deploying Gradio With Modal](../guides/deploying-gradio-with-modal/)[Developing Faster With Reload Mode](../guides/developing-faster-with-reload-mode/)[From Openapi Spec](../guides/from-openapi-spec/)[Gradio 6 Migration Guide](../guides/gradio-6-migration-guide/)[How To Use 3D Model Component](../guides/how-to-use-3D-model-component/)[Image Classification In Pytorch](../guides/image-classification-in-pytorch/)[Image Classification With Vision Transformers](../guides/image-classification-with-vision-transformers/)[Installing Gradio In A Virtual Environment](../guides/installing-gradio-in-a-virtual-environment/)[Named Entity Recognition](../guides/named-entity-recognition/)[Plot Component For Maps](../guides/plot-component-for-maps/)[Running Background Tasks](../guides/running-background-tasks/)[Running Gradio On Your Web Server With Nginx](../guides/running-gradio-on-your-web-server-with-nginx/)[Setting Up A Demo For Maximum Performance](../guides/setting-up-a-demo-for-maximum-performance/)[Styling The Gradio Dataframe](../guides/styling-the-gradio-dataframe/)[Theming Guide](../guides/theming-guide/)[Understanding Gradio Share Links](../guides/understanding-gradio-share-links/)[Using Flagging](../guides/using-flagging/)[Using Gradio For Tabular Workflows](../guides/using-gradio-for-tabular-workflows/)[Using Gradio In Other Programming Languages](../guides/using-gradio-in-other-programming-languages/)[Wrapping Layouts](../guides/wrapping-layouts/)

1. Streaming
2. Object Detection From Video

[‚Üê

Object Detection From Webcam With Webrtc](../guides/object-detection-from-webcam-with-webrtc/) [Conversational Chatbot

‚Üí](../guides/conversational-chatbot/)

# Streaming Object Detection from Video

In this guide we'll use the [RT-DETR](https://huggingface.co/docs/transformers/en/model_doc/rt_detr) model to detect objects in a user uploaded video. We'll stream the results from the server using the new video streaming features introduced in Gradio 5.0.

![video_object_detection_stream_latest](https://github.com/user-attachments/assets/4e27ac58-5ded-495d-9e0d-5e87e68b1355)

## Setting up the Model[![](data:image/svg+xml...)](#setting-up-the-model)

First, we'll install the following requirements in our system:

```
opencv-python
torch
transformers>=4.43.0
spaces
```

Then, we'll download the model from the Hugging Face Hub:

```
from transformers import RTDetrForObjectDetection, RTDetrImageProcessor

image_processor = RTDetrImageProcessor.from_pretrained("PekingU/rtdetr_r50vd")
model = RTDetrForObjectDetection.from_pretrained("PekingU/rtdetr_r50vd").to("cuda")
```

We're moving the model to the GPU. We'll be deploying our model to Hugging Face Spaces and running the inference in the [free ZeroGPU cluster](https://huggingface.co/zero-gpu-explorers).

## The Inference Function[![](data:image/svg+xml...)](#the-inference-function)

Our inference function will accept a video and a desired confidence threshold.
Object detection models identify many objects and assign a confidence score to each object. The lower the confidence, the higher the chance of a false positive. So we will let our users set the confidence threshold.

Our function will iterate over the frames in the video and run the RT-DETR model over each frame.
We will then draw the bounding boxes for each detected object in the frame and save the frame to a new output video.
The function will yield each output video in chunks of two seconds.

In order to keep inference times as low as possible on ZeroGPU (there is a time-based quota),
we will halve the original frames-per-second in the output video and resize the input frames to be half the original
size before running the model.

The code for the inference function is below - we'll go over it piece by piece.

```
import spaces
import cv2
from PIL import Image
import torch
import time
import numpy as np
import uuid

from draw_boxes import draw_bounding_boxes

SUBSAMPLE = 2

@spaces.GPU
def stream_object_detection(video, conf_threshold):
    cap = cv2.VideoCapture(video)

    # This means we will output mp4 videos
    video_codec = cv2.VideoWriter_fourcc(*"mp4v") # type: ignore
    fps = int(cap.get(cv2.CAP_PROP_FPS))

    desired_fps = fps // SUBSAMPLE
    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) // 2
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) // 2

    iterating, frame = cap.read()

    n_frames = 0

    # Use UUID to create a unique video file
    output_video_name = f"output_{uuid.uuid4()}.mp4"

    # Output Video
    output_video = cv2.VideoWriter(output_video_name, video_codec, desired_fps, (width, height)) # type: ignore
    batch = []

    while iterating:
        frame = cv2.resize( frame, (0,0), fx=0.5, fy=0.5)
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        if n_frames % SUBSAMPLE == 0:
            batch.append(frame)
        if len(batch) == 2 * desired_fps:
            inputs = image_processor(images=batch, return_tensors="pt").to("cuda")

            with torch.no_grad():
                outputs = model(**inputs)

            boxes = image_processor.post_process_object_detection(
                outputs,
                target_sizes=torch.tensor([(height, width)] * len(batch)),
                threshold=conf_threshold)

            for i, (array, box) in enumerate(zip(batch, boxes)):
                pil_image = draw_bounding_boxes(Image.fromarray(array), box, model, conf_threshold)
                frame = np.array(pil_image)
                # Convert RGB to BGR
                frame = frame[:, :, ::-1].copy()
                output_video.write(frame)

            batch = []
            output_video.release()
            yield output_video_name
            output_video_name = f"output_{uuid.uuid4()}.mp4"
            output_video = cv2.VideoWriter(output_video_name, video_codec, desired_fps, (width, height)) # type: ignore

        iterating, frame = cap.read()
        n_frames += 1
```

1. **Reading from the Video**

One of the industry standards for creating videos in python is OpenCV so we will use it in this app.

The `cap` variable is how we will read from the input video. Whenever we call `cap.read()`, we are reading the next frame in the video.

In order to stream video in Gradio, we need to yield a different video file for each "chunk" of the output video.
We create the next video file to write to with the `output_video = cv2.VideoWriter(output_video_name, video_codec, desired_fps, (width, height))` line. The `video_codec` is how we specify the type of video file. Only "mp4" and "ts" files are supported for video sreaming at the moment.

2. **The Inference Loop**

For each frame in the video, we will resize it to be half the size. OpenCV reads files in `BGR` format, so will convert to the expected `RGB` format of transfomers. That's what the first two lines of the while loop are doing.

We take every other frame and add it to a `batch` list so that the output video is half the original FPS. When the batch covers two seconds of video, we will run the model. The two second threshold was chosen to keep the processing time of each batch small enough so that video is smoothly displayed in the server while not requiring too many separate forward passes. In order for video streaming to work properly in Gradio, the batch size should be at least 1 second.

We run the forward pass of the model and then use the `post_process_object_detection` method of the model to scale the detected bounding boxes to the size of the input frame.

We make use of a custom function to draw the bounding boxes (source [here](https://huggingface.co/spaces/gradio/rt-detr-object-detection/blob/main/draw_boxes.py#L14)). We then have to convert from `RGB` to `BGR` before writing back to the output video.

Once we have finished processing the batch, we create a new output video file for the next batch.

## The Gradio Demo[![](data:image/svg+xml...)](#the-gradio-demo)

The UI code is pretty similar to other kinds of Gradio apps.
We'll use a standard two-column layout so that users can see the input and output videos side by side.

In order for streaming to work, we have to set `streaming=True` in the output video. Setting the video
to autoplay is not necessary but it's a better experience for users.

```
import gradio as gr

with gr.Blocks() as app:
    gr.HTML(
        """
    <h1 style='text-align: center'>
    Video Object Detection with <a href='https://huggingface.co/PekingU/rtdetr_r101vd_coco_o365' target='_blank'>RT-DETR</a>
    </h1>
    """)
    with gr.Row():
        with gr.Column():
            video = gr.Video(label="Video Source")
            conf_threshold = gr.Slider(
                label="Confidence Threshold",
                minimum=0.0,
                maximum=1.0,
                step=0.05,
                value=0.30,
            )
        with gr.Column():
            output_video = gr.Video(label="Processed Video", streaming=True, autoplay=True)

    video.upload(
        fn=stream_object_detection,
        inputs=[video, conf_threshold],
        outputs=[output_video],
    )
```

## Conclusion[![](data:image/svg+xml...)](#conclusion)

You can check out our demo hosted on Hugging Face Spaces [here](https://huggingface.co/spaces/gradio/rt-detr-object-detection).

It is also embedded on this page below

[‚Üê

Object Detection From Webcam With Webrtc](../guides/object-detection-from-webcam-with-webrtc/) [Conversational Chatbot

‚Üí](../guides/conversational-chatbot/)

[![Gradio logo](/_app/immutable/assets/gradio.CHB5adID.svg)](/)

[Status](https://status.gradio.app) [![Twitter logo](data:image/svg+xml...)](https://twitter.com/Gradio) [![Github logo](data:image/svg+xml...)](https://github.com/gradio-app/gradio)