**MCP's 1st Birthday Hackathon**

[Watch Now ‚Üí](https://www.youtube.com/watch?v=6C2JRt2Wi5o)

[![Gradio logo](/_app/immutable/assets/gradio.CHB5adID.svg)](/)  [‚ö° Quickstart](/guides/quickstart) [‚úçÔ∏è Docs](/docs) [üé¢ Playground](/playground) [üñºÔ∏è Custom Components](/custom-components/gallery)

üñê Community

Search Search

‚åòK

Getting Started

[Quickstart](../guides/quickstart/)

Building Interfaces

[The Interface Class](../guides/the-interface-class/)[More On Examples](../guides/more-on-examples/)[Flagging](../guides/flagging/)[Interface State](../guides/interface-state/)[Reactive Interfaces](../guides/reactive-interfaces/)[Four Kinds Of Interfaces](../guides/four-kinds-of-interfaces/)

Building With Blocks

[Blocks And Event Listeners](../guides/blocks-and-event-listeners/)[Controlling Layout](../guides/controlling-layout/)[State In Blocks](../guides/state-in-blocks/)[Dynamic Apps With Render Decorator](../guides/dynamic-apps-with-render-decorator/)[More Blocks Features](../guides/more-blocks-features/)[Custom CSS And JS](../guides/custom-CSS-and-JS/)[Using Blocks Like Functions](../guides/using-blocks-like-functions/)

Additional Features

[Queuing](../guides/queuing/)[Streaming Outputs](../guides/streaming-outputs/)[Streaming Inputs](../guides/streaming-inputs/)[Alerts](../guides/alerts/)[Progress Bars](../guides/progress-bars/)[Batch Functions](../guides/batch-functions/)[Sharing Your App](../guides/sharing-your-app/)[File Access](../guides/file-access/)[Multipage Apps](../guides/multipage-apps/)[Environment Variables](../guides/environment-variables/)[Resource Cleanup](../guides/resource-cleanup/)[Themes](../guides/themes/)[Client Side Functions](../guides/client-side-functions/)[View Api Page](../guides/view-api-page/)[Internationalization](../guides/internationalization/)

Chatbots

[Creating A Chatbot Fast](../guides/creating-a-chatbot-fast/)[Chatinterface Examples](../guides/chatinterface-examples/)[Agents And Tool Usage](../guides/agents-and-tool-usage/)[Creating A Custom Chatbot With Blocks](../guides/creating-a-custom-chatbot-with-blocks/)[Chatbot Specific Events](../guides/chatbot-specific-events/)[Creating A Discord Bot From A Gradio App](../guides/creating-a-discord-bot-from-a-gradio-app/)[Creating A Slack Bot From A Gradio App](../guides/creating-a-slack-bot-from-a-gradio-app/)[Creating A Website Widget From A Gradio Chatbot](../guides/creating-a-website-widget-from-a-gradio-chatbot/)

Data Science And Plots

[Creating Plots](../guides/creating-plots/)[Time Plots](../guides/time-plots/)[Filters Tables And Stats](../guides/filters-tables-and-stats/)[Connecting To A Database](../guides/connecting-to-a-database/)

Streaming

[Streaming Ai Generated Audio](../guides/streaming-ai-generated-audio/)[Object Detection From Webcam With Webrtc](../guides/object-detection-from-webcam-with-webrtc/)[Object Detection From Video](../guides/object-detection-from-video/)[Conversational Chatbot](../guides/conversational-chatbot/)[Real Time Speech Recognition](../guides/real-time-speech-recognition/)[Automatic Voice Detection](../guides/automatic-voice-detection/)

Custom Components

[Custom Components In Five Minutes](../guides/custom-components-in-five-minutes/)[Key Component Concepts](../guides/key-component-concepts/)[Configuration](../guides/configuration/)[Backend](../guides/backend/)[Frontend](../guides/frontend/)[Frequently Asked Questions](../guides/frequently-asked-questions/)[Pdf Component Example](../guides/pdf-component-example/)[Multimodal Chatbot Part1](../guides/multimodal-chatbot-part1/)[Documenting Custom Components](../guides/documenting-custom-components/)

Gradio Clients And Lite

[Getting Started With The Python Client](../guides/getting-started-with-the-python-client/)[Getting Started With The Js Client](../guides/getting-started-with-the-js-client/)[Querying Gradio Apps With Curl](../guides/querying-gradio-apps-with-curl/)[Gradio And Llm Agents](../guides/gradio-and-llm-agents/)[Fastapi App With The Gradio Client](../guides/fastapi-app-with-the-gradio-client/)

Mcp

[Building Mcp Server With Gradio](../guides/building-mcp-server-with-gradio/)[File Upload Mcp](../guides/file-upload-mcp/)[Building An Mcp Client With Gradio](../guides/building-an-mcp-client-with-gradio/)[Using Docs Mcp](../guides/using-docs-mcp/)

Other Tutorials

[Using Hugging Face Integrations](../guides/using-hugging-face-integrations/)[Gradio And Comet](../guides/Gradio-and-Comet/)[Gradio And ONNX On Hugging Face](../guides/Gradio-and-ONNX-on-Hugging-Face/)[Gradio And Wandb Integration](../guides/Gradio-and-Wandb-Integration/)[Create Immersive Demo](../guides/create-immersive-demo/)[Create Your Own Friends With A Gan](../guides/create-your-own-friends-with-a-gan/)[Creating A Dashboard From Bigquery Data](../guides/creating-a-dashboard-from-bigquery-data/)[Creating A Dashboard From Supabase Data](../guides/creating-a-dashboard-from-supabase-data/)[Creating A Realtime Dashboard From Google Sheets](../guides/creating-a-realtime-dashboard-from-google-sheets/)[Deploying Gradio With Disco](../guides/deploying-gradio-with-disco/)[Deploying Gradio With Docker](../guides/deploying-gradio-with-docker/)[Deploying Gradio With Modal](../guides/deploying-gradio-with-modal/)[Developing Faster With Reload Mode](../guides/developing-faster-with-reload-mode/)[From Openapi Spec](../guides/from-openapi-spec/)[Gradio 6 Migration Guide](../guides/gradio-6-migration-guide/)[How To Use 3D Model Component](../guides/how-to-use-3D-model-component/)[Image Classification In Pytorch](../guides/image-classification-in-pytorch/)[Image Classification With Vision Transformers](../guides/image-classification-with-vision-transformers/)[Installing Gradio In A Virtual Environment](../guides/installing-gradio-in-a-virtual-environment/)[Named Entity Recognition](../guides/named-entity-recognition/)[Plot Component For Maps](../guides/plot-component-for-maps/)[Running Background Tasks](../guides/running-background-tasks/)[Running Gradio On Your Web Server With Nginx](../guides/running-gradio-on-your-web-server-with-nginx/)[Setting Up A Demo For Maximum Performance](../guides/setting-up-a-demo-for-maximum-performance/)[Styling The Gradio Dataframe](../guides/styling-the-gradio-dataframe/)[Theming Guide](../guides/theming-guide/)[Understanding Gradio Share Links](../guides/understanding-gradio-share-links/)[Using Flagging](../guides/using-flagging/)[Using Gradio For Tabular Workflows](../guides/using-gradio-for-tabular-workflows/)[Using Gradio In Other Programming Languages](../guides/using-gradio-in-other-programming-languages/)[Wrapping Layouts](../guides/wrapping-layouts/)

5.49.14.44.1main

Getting Started

[Quickstart](../guides/quickstart/)

Building Interfaces

[The Interface Class](../guides/the-interface-class/)[More On Examples](../guides/more-on-examples/)[Flagging](../guides/flagging/)[Interface State](../guides/interface-state/)[Reactive Interfaces](../guides/reactive-interfaces/)[Four Kinds Of Interfaces](../guides/four-kinds-of-interfaces/)

Building With Blocks

[Blocks And Event Listeners](../guides/blocks-and-event-listeners/)[Controlling Layout](../guides/controlling-layout/)[State In Blocks](../guides/state-in-blocks/)[Dynamic Apps With Render Decorator](../guides/dynamic-apps-with-render-decorator/)[More Blocks Features](../guides/more-blocks-features/)[Custom CSS And JS](../guides/custom-CSS-and-JS/)[Using Blocks Like Functions](../guides/using-blocks-like-functions/)

Additional Features

[Queuing](../guides/queuing/)[Streaming Outputs](../guides/streaming-outputs/)[Streaming Inputs](../guides/streaming-inputs/)[Alerts](../guides/alerts/)[Progress Bars](../guides/progress-bars/)[Batch Functions](../guides/batch-functions/)[Sharing Your App](../guides/sharing-your-app/)[File Access](../guides/file-access/)[Multipage Apps](../guides/multipage-apps/)[Environment Variables](../guides/environment-variables/)[Resource Cleanup](../guides/resource-cleanup/)[Themes](../guides/themes/)[Client Side Functions](../guides/client-side-functions/)[View Api Page](../guides/view-api-page/)[Internationalization](../guides/internationalization/)

Chatbots

[Creating A Chatbot Fast](../guides/creating-a-chatbot-fast/)[Chatinterface Examples](../guides/chatinterface-examples/)[Agents And Tool Usage](../guides/agents-and-tool-usage/)[Creating A Custom Chatbot With Blocks](../guides/creating-a-custom-chatbot-with-blocks/)[Chatbot Specific Events](../guides/chatbot-specific-events/)[Creating A Discord Bot From A Gradio App](../guides/creating-a-discord-bot-from-a-gradio-app/)[Creating A Slack Bot From A Gradio App](../guides/creating-a-slack-bot-from-a-gradio-app/)[Creating A Website Widget From A Gradio Chatbot](../guides/creating-a-website-widget-from-a-gradio-chatbot/)

Data Science And Plots

[Creating Plots](../guides/creating-plots/)[Time Plots](../guides/time-plots/)[Filters Tables And Stats](../guides/filters-tables-and-stats/)[Connecting To A Database](../guides/connecting-to-a-database/)

Streaming

[Streaming Ai Generated Audio](../guides/streaming-ai-generated-audio/)[Object Detection From Webcam With Webrtc](../guides/object-detection-from-webcam-with-webrtc/)[Object Detection From Video](../guides/object-detection-from-video/)[Conversational Chatbot](../guides/conversational-chatbot/)[Real Time Speech Recognition](../guides/real-time-speech-recognition/)[Automatic Voice Detection](../guides/automatic-voice-detection/)

[Introduction](#introduction)[Background](#background)[Key Components](#key-components)[Setting Up the Environment](#setting-up-the-environment)[State Management for Seamless Conversations](#state-management-for-seamless-conversations)[Transcribing Audio with Whisper on Groq](#transcribing-audio-with-whisper-on-groq)[Adding Conversational Intelligence with LLM Integration](#adding-conversational-intelligence-with-llm-integration)[Voice Activity Detection for Hands-Free Interaction](#voice-activity-detection-for-hands-free-interaction)[Building a User Interface with Gradio](#building-a-user-interface-with-gradio)[Handling Recording and Responses](#handling-recording-and-responses)[Summary](#summary)

Custom Components

[Custom Components In Five Minutes](../guides/custom-components-in-five-minutes/)[Key Component Concepts](../guides/key-component-concepts/)[Configuration](../guides/configuration/)[Backend](../guides/backend/)[Frontend](../guides/frontend/)[Frequently Asked Questions](../guides/frequently-asked-questions/)[Pdf Component Example](../guides/pdf-component-example/)[Multimodal Chatbot Part1](../guides/multimodal-chatbot-part1/)[Documenting Custom Components](../guides/documenting-custom-components/)

Gradio Clients And Lite

[Getting Started With The Python Client](../guides/getting-started-with-the-python-client/)[Getting Started With The Js Client](../guides/getting-started-with-the-js-client/)[Querying Gradio Apps With Curl](../guides/querying-gradio-apps-with-curl/)[Gradio And Llm Agents](../guides/gradio-and-llm-agents/)[Fastapi App With The Gradio Client](../guides/fastapi-app-with-the-gradio-client/)

Mcp

[Building Mcp Server With Gradio](../guides/building-mcp-server-with-gradio/)[File Upload Mcp](../guides/file-upload-mcp/)[Building An Mcp Client With Gradio](../guides/building-an-mcp-client-with-gradio/)[Using Docs Mcp](../guides/using-docs-mcp/)

Other Tutorials [ show ]

[Using Hugging Face Integrations](../guides/using-hugging-face-integrations/)[Gradio And Comet](../guides/Gradio-and-Comet/)[Gradio And ONNX On Hugging Face](../guides/Gradio-and-ONNX-on-Hugging-Face/)[Gradio And Wandb Integration](../guides/Gradio-and-Wandb-Integration/)[Create Immersive Demo](../guides/create-immersive-demo/)[Create Your Own Friends With A Gan](../guides/create-your-own-friends-with-a-gan/)[Creating A Dashboard From Bigquery Data](../guides/creating-a-dashboard-from-bigquery-data/)[Creating A Dashboard From Supabase Data](../guides/creating-a-dashboard-from-supabase-data/)[Creating A Realtime Dashboard From Google Sheets](../guides/creating-a-realtime-dashboard-from-google-sheets/)[Deploying Gradio With Disco](../guides/deploying-gradio-with-disco/)[Deploying Gradio With Docker](../guides/deploying-gradio-with-docker/)[Deploying Gradio With Modal](../guides/deploying-gradio-with-modal/)[Developing Faster With Reload Mode](../guides/developing-faster-with-reload-mode/)[From Openapi Spec](../guides/from-openapi-spec/)[Gradio 6 Migration Guide](../guides/gradio-6-migration-guide/)[How To Use 3D Model Component](../guides/how-to-use-3D-model-component/)[Image Classification In Pytorch](../guides/image-classification-in-pytorch/)[Image Classification With Vision Transformers](../guides/image-classification-with-vision-transformers/)[Installing Gradio In A Virtual Environment](../guides/installing-gradio-in-a-virtual-environment/)[Named Entity Recognition](../guides/named-entity-recognition/)[Plot Component For Maps](../guides/plot-component-for-maps/)[Running Background Tasks](../guides/running-background-tasks/)[Running Gradio On Your Web Server With Nginx](../guides/running-gradio-on-your-web-server-with-nginx/)[Setting Up A Demo For Maximum Performance](../guides/setting-up-a-demo-for-maximum-performance/)[Styling The Gradio Dataframe](../guides/styling-the-gradio-dataframe/)[Theming Guide](../guides/theming-guide/)[Understanding Gradio Share Links](../guides/understanding-gradio-share-links/)[Using Flagging](../guides/using-flagging/)[Using Gradio For Tabular Workflows](../guides/using-gradio-for-tabular-workflows/)[Using Gradio In Other Programming Languages](../guides/using-gradio-in-other-programming-languages/)[Wrapping Layouts](../guides/wrapping-layouts/)

1. Streaming
2. Automatic Voice Detection

[‚Üê

Real Time Speech Recognition](../guides/real-time-speech-recognition/) [Custom Components In Five Minutes

‚Üí](../guides/custom-components-in-five-minutes/)

# Multimodal Gradio App Powered by Groq with Automatic Speech Detection

## Introduction[![](data:image/svg+xml...)](#introduction)

Modern voice applications should feel natural and responsive, moving beyond the traditional "click-to-record" pattern. By combining Groq's fast inference capabilities with automatic speech detection, we can create a more intuitive interaction model where users can simply start talking whenever they want to engage with the AI.

> Credits: VAD and Gradio code inspired by [WillHeld's Diva-audio-chat](https://huggingface.co/spaces/WillHeld/diva-audio-chat/tree/main).

In this tutorial, you will learn how to create a multimodal Gradio and Groq app that has automatic speech detection. You can also watch the full video tutorial which includes a demo of the application:

## Background[![](data:image/svg+xml...)](#background)

Many voice apps currently work by the user clicking record, speaking, then stopping the recording. While this can be a powerful demo, the most natural mode of interaction with voice requires the app to dynamically detect when the user is speaking, so they can talk back and forth without having to continually click a record button.

Creating a natural interaction with voice and text requires a dynamic and low-latency response. Thus, we need both automatic voice detection and fast inference. With @ricky0123/vad-web powering speech detection and Groq powering the LLM, both of these requirements are met. Groq provides a lightning fast response, and Gradio allows for easy creation of impressively functional apps.

This tutorial shows you how to build a calorie tracking app where you speak to an AI that automatically detects when you start and stop your response, and provides its own text response back to guide you with questions that allow it to give a calorie estimate of your last meal.

## Key Components[![](data:image/svg+xml...)](#key-components)

* **Gradio**: Provides the web interface and audio handling capabilities
* **@ricky0123/vad-web**: Handles voice activity detection
* **Groq**: Powers fast LLM inference for natural conversations
* **Whisper**: Transcribes speech to text

### Setting Up the Environment[![](data:image/svg+xml...)](#setting-up-the-environment)

First, let‚Äôs install and import our essential libraries and set up a client for using the Groq API. Here‚Äôs how to do it:

`requirements.txt`

```
gradio
groq
numpy
soundfile
librosa
spaces
xxhash
datasets
```

`app.py`

```
import groq
import gradio as gr
import soundfile as sf
from dataclasses import dataclass, field
import os

# Initialize Groq client securely
api_key = os.environ.get("GROQ_API_KEY")
if not api_key:
    raise ValueError("Please set the GROQ_API_KEY environment variable.")
client = groq.Client(api_key=api_key)
```

Here, we‚Äôre pulling in key libraries to interact with the Groq API, build a sleek UI with Gradio, and handle audio data. We‚Äôre accessing the Groq API key securely with a key stored in an environment variable, which is a security best practice for avoiding leaking the API key.

---

### State Management for Seamless Conversations[![](data:image/svg+xml...)](#state-management-for-seamless-conversations)

We need a way to keep track of our conversation history, so the chatbot remembers past interactions, and manage other states like whether recording is currently active. To do this, let‚Äôs create an `AppState` class:

```
@dataclass
class AppState:
    conversation: list = field(default_factory=list)
    stopped: bool = False
    model_outs: Any = None
```

Our `AppState` class is a handy tool for managing conversation history and tracking whether recording is on or off. Each instance will have its own fresh list of conversations, making sure chat history is isolated to each session.

---

### Transcribing Audio with Whisper on Groq[![](data:image/svg+xml...)](#transcribing-audio-with-whisper-on-groq)

Next, we‚Äôll create a function to transcribe the user‚Äôs audio input into text using Whisper, a powerful transcription model hosted on Groq. This transcription will also help us determine whether there‚Äôs meaningful speech in the input. Here‚Äôs how:

```
def transcribe_audio(client, file_name):
    if file_name is None:
        return None

    try:
        with open(file_name, "rb") as audio_file:
            response = client.audio.transcriptions.with_raw_response.create(
                model="whisper-large-v3-turbo",
                file=("audio.wav", audio_file),
                response_format="verbose_json",
            )
            completion = process_whisper_response(response.parse())
            return completion
    except Exception as e:
        print(f"Error in transcription: {e}")
        return f"Error in transcription: {str(e)}"
```

This function opens the audio file and sends it to Groq‚Äôs Whisper model for transcription, requesting detailed JSON output. verbose\_json is needed to get information to determine if speech was included in the audio. We also handle any potential errors so our app doesn‚Äôt fully crash if there‚Äôs an issue with the API request.

```
def process_whisper_response(completion):
    """
    Process Whisper transcription response and return text or null based on no_speech_prob

    Args:
        completion: Whisper transcription response object

    Returns:
        str or None: Transcribed text if no_speech_prob <= 0.7, otherwise None
    """
    if completion.segments and len(completion.segments) > 0:
        no_speech_prob = completion.segments[0].get('no_speech_prob', 0)
        print("No speech prob:", no_speech_prob)

        if no_speech_prob > 0.7:
            return None

        return completion.text.strip()

    return None
```

We also need to interpret the audio data response. The process\_whisper\_response function takes the resulting completion from Whisper and checks if the audio was just background noise or had actual speaking that was transcribed. It uses a threshold of 0.7 to interpret the no\_speech\_prob, and will return None if there was no speech. Otherwise, it will return the text transcript of the conversational response from the human.

---

### Adding Conversational Intelligence with LLM Integration[![](data:image/svg+xml...)](#adding-conversational-intelligence-with-llm-integration)

Our chatbot needs to provide intelligent, friendly responses that flow naturally. We‚Äôll use a Groq-hosted Llama-3.2 for this:

```
def generate_chat_completion(client, history):
    messages = []
    messages.append(
        {
            "role": "system",
            "content": "In conversation with the user, ask questions to estimate and provide (1) total calories, (2) protein, carbs, and fat in grams, (3) fiber and sugar content. Only ask *one question at a time*. Be conversational and natural.",
        }
    )

    for message in history:
        messages.append(message)

    try:
        completion = client.chat.completions.create(
            model="llama-3.2-11b-vision-preview",
            messages=messages,
        )
        return completion.choices[0].message.content
    except Exception as e:
        return f"Error in generating chat completion: {str(e)}"
```

We‚Äôre defining a system prompt to guide the chatbot‚Äôs behavior, ensuring it asks one question at a time and keeps things conversational. This setup also includes error handling to ensure the app gracefully manages any issues.

---

### Voice Activity Detection for Hands-Free Interaction[![](data:image/svg+xml...)](#voice-activity-detection-for-hands-free-interaction)

To make our chatbot hands-free, we‚Äôll add Voice Activity Detection (VAD) to automatically detect when someone starts or stops speaking. Here‚Äôs how to implement it using ONNX in JavaScript:

```
async function main() {
  const script1 = document.createElement("script");
  script1.src = "https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.js";
  document.head.appendChild(script1)
  const script2 = document.createElement("script");
  script2.onload = async () =>  {
    console.log("vad loaded");
    var record = document.querySelector('.record-button');
    record.textContent = "Just Start Talking!"

    const myvad = await vad.MicVAD.new({
      onSpeechStart: () => {
        var record = document.querySelector('.record-button');
        var player = document.querySelector('#streaming-out')
        if (record != null && (player == null || player.paused)) {
          record.click();
        }
      },
      onSpeechEnd: (audio) => {
        var stop = document.querySelector('.stop-button');
        if (stop != null) {
          stop.click();
        }
      }
    })
    myvad.start()
  }
  script2.src = "https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.7/dist/bundle.min.js";
}
```

This script loads our VAD model and sets up functions to start and stop recording automatically. When the user starts speaking, it triggers the recording, and when they stop, it ends the recording.

---

### Building a User Interface with Gradio[![](data:image/svg+xml...)](#building-a-user-interface-with-gradio)

Now, let‚Äôs create an intuitive and visually appealing user interface with Gradio. This interface will include an audio input for capturing voice, a chat window for displaying responses, and state management to keep things synchronized.

```
with gr.Blocks(theme=theme, js=js) as demo:
    with gr.Row():
        input_audio = gr.Audio(
            label="Input Audio",
            sources=["microphone"],
            type="numpy",
            streaming=False,
            waveform_options=gr.WaveformOptions(waveform_color="#B83A4B"),
        )
    with gr.Row():
        chatbot = gr.Chatbot(label="Conversation", type="messages")
    state = gr.State(value=AppState())
```

In this code block, we‚Äôre using Gradio‚Äôs `Blocks` API to create an interface with an audio input, a chat display, and an application state manager. The color customization for the waveform adds a nice visual touch.

---

### Handling Recording and Responses[![](data:image/svg+xml...)](#handling-recording-and-responses)

Finally, let‚Äôs link the recording and response components to ensure the app reacts smoothly to user inputs and provides responses in real-time.

```
    stream = input_audio.start_recording(
        process_audio,
        [input_audio, state],
        [input_audio, state],
    )
    respond = input_audio.stop_recording(
        response, [state, input_audio], [state, chatbot]
    )
```

These lines set up event listeners for starting and stopping the recording, processing the audio input, and generating responses. By linking these events, we create a cohesive experience where users can simply talk, and the chatbot handles the rest.

---

## Summary[![](data:image/svg+xml...)](#summary)

1. When you open the app, the VAD system automatically initializes and starts listening for speech
2. As soon as you start talking, it triggers the recording automatically
3. When you stop speaking, the recording ends and:
   * The audio is transcribed using Whisper
   * The transcribed text is sent to the LLM
   * The LLM generates a response about calorie tracking
   * The response is displayed in the chat interface
4. This creates a natural back-and-forth conversation where you can simply talk about your meals and get instant feedback on nutritional content

This app demonstrates how to create a natural voice interface that feels responsive and intuitive. By combining Groq's fast inference with automatic speech detection, we've eliminated the need for manual recording controls while maintaining high-quality interactions. The result is a practical calorie tracking assistant that users can simply talk to as naturally as they would to a human nutritionist.

Link to GitHub repository: [Groq Gradio Basics](https://github.com/bklieger-groq/gradio-groq-basics/tree/main/calorie-tracker)

[‚Üê

Real Time Speech Recognition](../guides/real-time-speech-recognition/) [Custom Components In Five Minutes

‚Üí](../guides/custom-components-in-five-minutes/)

[![Gradio logo](/_app/immutable/assets/gradio.CHB5adID.svg)](/)

[Status](https://status.gradio.app) [![Twitter logo](data:image/svg+xml...)](https://twitter.com/Gradio) [![Github logo](data:image/svg+xml...)](https://github.com/gradio-app/gradio)